{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18a2fc2-081d-4dbb-a179-29af2149ffad",
   "metadata": {},
   "source": [
    "## A simple example of keyword matching using gloVe embedding vectors of Wikipedia\n",
    "\n",
    "### Step 1: Install the following packages for this Sample (requirements.txt is included)\n",
    " - numpy\n",
    " - scipy\n",
    " - matplotlib\n",
    " - scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b433865-dfe5-4e3e-8ad3-f946c62afa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from -r 001-requirements.txt (line 1)) (1.25.0)\n",
      "Requirement already satisfied: scipy in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from -r 001-requirements.txt (line 2)) (1.11.0)\n",
      "Requirement already satisfied: matplotlib in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from -r 001-requirements.txt (line 3)) (3.7.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from -r 001-requirements.txt (line 4)) (1.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from matplotlib->-r 001-requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from matplotlib->-r 001-requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from matplotlib->-r 001-requirements.txt (line 3)) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from matplotlib->-r 001-requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from matplotlib->-r 001-requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from matplotlib->-r 001-requirements.txt (line 3)) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from matplotlib->-r 001-requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from matplotlib->-r 001-requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from scikit-learn->-r 001-requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from scikit-learn->-r 001-requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/spm1976/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->-r 001-requirements.txt (line 3)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -r 001-requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1240fabe-9d3a-4795-b390-b0941c80ea94",
   "metadata": {},
   "source": [
    "## Step 2: Download and unzip the gloVe embedding vectors for words in Wikipedia\n",
    "\n",
    "Head over to https://nlp.stanford.edu/projects/glove/.\n",
    "<p>\n",
    "Then underneath “Download pre-trained word vectors,” you can choose any of the four options for different sizes or training datasets.\n",
    "I have chosen the Wikipedia 2014 + Gigaword 5 vectors. You can download those exact vectors at http://nlp.stanford.edu/data/glove.6B.zip (WARNING: THIS IS A 822 MB DOWNLOAD)\n",
    "    \n",
    "Note: The Stanford library is having an outage as-of writing this article, so I was able to retrieve and compress the file from Kaggle.\n",
    "    \n",
    "https://cs.stanford.edu/srcf_404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cdb4745-be09-43ba-a441-12dc77f8e84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: L_GLOVE_ZIPFILE: command not found\n",
      "--2023-06-28 12:18:10--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cs.stanford.edu/srcf_404 [following]\n",
      "--2023-06-28 12:18:11--  https://cs.stanford.edu/srcf_404\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘data/glove/glove.6B.zip’\n",
      "\n",
      "     0K .......... .......... .......... .........              460K=0.09s\n",
      "\n",
      "2023-06-28 12:18:11 (460 KB/s) - ‘data/glove/glove.6B.zip’ saved [40360]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "L_GLOVE_ZIPFILE = 'data/glove/glove.6B.zip'\n",
    "\n",
    "if [[ ! -f ${L_GLOVE_ZIPFILE} ]]; then\n",
    "    mkdir -p data/glove\n",
    "    wget https://nlp.stanford.edu/data/glove.6B.zip -O data/glove/glove.6B.zip\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b593a-b842-40fb-ae3c-75fcff23d4cf",
   "metadata": {},
   "source": [
    "### Step 3: Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17644b8-c8a2-4c9e-a898-d0a6d37286c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f9034b-3d95-417c-8775-816a21d583cb",
   "metadata": {},
   "source": [
    "### Step 4: Load the enbedding vectors\n",
    "\n",
    "The vector files that we downloaded is formatted in a text file by a word, followed by N numbers for each line.\n",
    "The N numbers describe the vector of the word's position. N will vary depending on the vectors you use from the zip file.\n",
    "I am using glove.6B.50d, so I will 50 100 N in each line.\n",
    "\n",
    "```\n",
    "python 0.24934 0.68318 -0.044711 -1.3842 -0.0073079 0.651 -0.33958 -0.19785 -0.33925 0.26691 -0.033062 0.15915 0.89547 0.53999 -0.55817 0.46245 0.36722 0.1889 0.83189 0.81421 -0.11835 -0.53463 0.24158 -0.038864 1.1907 0.79353 -0.12308 0.6642 -0.77619 -0.45713 -1.054 -0.20557 -0.13296 0.12239 0.88458 1.024 0.32288 0.82105 -0.069367 0.024211 -0.51418 0.8727 0.25759 0.91526 -0.64221 0.041159 -0.60208 0.54631 0.66076 0.19796 -1.1393 0.79514 0.45966 -0.18463 -0.64131 -0.24929 -0.40194 -0.50786 0.80579 0.53365 0.52732 0.39247 -0.29884 0.009585 0.99953 -0.061279 0.71936 0.32901 -0.052772 0.67135 -0.80251 -0.25789 0.49615 0.48081 -0.68403 -0.012239 0.048201 0.29461 0.20614 0.33556 -0.64167 -0.64708 0.13377 -0.12574 -0.46382 1.3878 0.95636 -0.067869 -0.0017411 0.52965 0.45668 0.61041 -0.11514 0.42627 0.17342 -0.7995 -0.24502 -0.60886 -0.38469 -0.4797\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01e4a52-268a-4939-b5aa-c985a969550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = dict()\n",
    "\n",
    "with gzip.open(\"data/glove/glove.6B.50d.txt.gz\", 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector\n",
    "\n",
    "#print(list(embeddings_dict.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d4023-ab32-465f-9a9f-0cf1fd779b99",
   "metadata": {},
   "source": [
    "# Step 5: define a function that will find the closest words to provided keyword\n",
    "\n",
    "The sorted method takes an iterable as a parameter and sorts it by the provided key. we can get the iterable from the dictionary of embeddings by using the *keys()* method of dict.\n",
    "<p>\n",
    "The built-in euclidean distance method in scipy's spatial package is used to calculate distance between each word embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000794f5-4568-436b-8685-6abe5886619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embeddings(embedding):\n",
    "    return sorted(embeddings_dict.keys(), key=lambda word: spatial.distance.euclidean(embeddings_dict[word], embedding))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae4de20-bd84-496b-b58b-29d230928ee9",
   "metadata": {},
   "source": [
    "### Step 6: Find words closest related to a keyword\n",
    "\n",
    "Since we now have a method that will measure distance between words that are already known, we can call this to find the words that are closest to the keyword.\n",
    "\n",
    "```\n",
    "find_closest_embeddings(embeddings_dict[\"python\"])\n",
    "```\n",
    "Sine this will return every match that we have in embeddings, I am limiting this to the top 10 matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149af473-015f-4944-a662-8c98f190ddcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['math',\n",
       " 'maths',\n",
       " 'instruction',\n",
       " 'curriculum',\n",
       " 'graders',\n",
       " 'graduates',\n",
       " 'lesson',\n",
       " 'learning',\n",
       " 'curricula',\n",
       " 'undergraduate']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_embeddings(embeddings_dict['math'])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde333e3-cf98-4989-a4f8-9d0f10dbbcc4",
   "metadata": {},
   "source": [
    "As you will notice, the first match is always the keyword. It can be ignored by limiting the results as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea164fd4-5b00-468c-8318-c270dc1df7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maths',\n",
       " 'instruction',\n",
       " 'curriculum',\n",
       " 'graders',\n",
       " 'graduates',\n",
       " 'lesson',\n",
       " 'learning',\n",
       " 'curricula',\n",
       " 'undergraduate']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_embeddings(embeddings_dict['math'])[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdccebe-9cc4-49c3-8987-10241fae0bea",
   "metadata": {},
   "source": [
    "## Math with keywords\n",
    "Now that we have a created a method that we can use to map closest keywords, we can now use this same function to do math equations - just like we would do with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "804fc6b8-37e4-4de8-a2f8-95781027bdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['luggage', 'baggage', 'cargo', 'bags', 'airplane']\n"
     ]
    }
   ],
   "source": [
    "equation = embeddings_dict['bulky'] + embeddings_dict['luggage'] + embeddings_dict['airplane']\n",
    "\n",
    "closest_matches = find_closest_embeddings(equation)[:5]\n",
    "\n",
    "print(closest_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71e7b1-e7d2-417b-b287-a0ae881d14d6",
   "metadata": {},
   "source": [
    "This returns luggage and baggage as its top results, so this seems logical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303d0d9-41ae-4f32-bd0e-edcd8281506e",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
